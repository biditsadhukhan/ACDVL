{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Here, we will try to segment skin leison using U-Net architecture."
      ],
      "metadata": {
        "id": "yuykHyDPbMc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "01/03/2024\n",
        "\n",
        "Author = <a href=\"https://jimut123.github.io/\" target=\"_blank\" alt=\"Jimut\">Jimut</a>"
      ],
      "metadata": {
        "id": "f0I0q-bLdIj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to the data for single class segmentation: https://drive.google.com/drive/u/0/folders/1JWRW_GuolArm3mPsO3Elf1SFJEZPzWBR"
      ],
      "metadata": {
        "id": "kHXJ6S8BYVfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data for segmentation, pre-process it to load in the train-val-test pipeline"
      ],
      "metadata": {
        "id": "qLsUcWM2dcyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 12VD4JR_ORiOoIuZHfy9xhO_QXcP5CEzU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LluMa4nlX1h2",
        "outputId": "cb0c328f-d155-4843-f892-549332ca81de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12VD4JR_ORiOoIuZHfy9xhO_QXcP5CEzU\n",
            "From (redirected): https://drive.google.com/uc?id=12VD4JR_ORiOoIuZHfy9xhO_QXcP5CEzU&confirm=t&uuid=c4ba6ffc-c7ae-4636-8b1e-369609ebb97b\n",
            "To: /content/skin_lesion.zip\n",
            "100% 50.2M/50.2M [00:00<00:00, 118MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -qq skin_lesion.zip"
      ],
      "metadata": {
        "id": "H352xS4EX1fE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531e3317-d839-4248-9d4b-f5c29131c850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace ph2_resized/trainx/X_img_0.bmp? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the train-val-test set"
      ],
      "metadata": {
        "id": "DWxGX4FwcMOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "\n",
        "FOLDER_NAME = \"train_imgs\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FOLDER_NAME = \"val_imgs\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FOLDER_NAME = \"test_imgs\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FOLDER_NAME = \"train_masks\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FOLDER_NAME = \"val_masks\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "FOLDER_NAME = \"test_masks\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "ALL_IMAGES = glob.glob('trainx/*.bmp')\n",
        "train_per = 70\n",
        "vali_per = 10\n",
        "test_per = 20\n",
        "\n",
        "TRAIN_IMG_NUM = int(train_per*len(ALL_IMAGES)/100)\n",
        "VALID_IMG_NUM = int(vali_per*len(ALL_IMAGES)/100)\n",
        "TEST_IMG_NUM = TRAIN_IMG_NUM + VALID_IMG_NUM\n",
        "\n",
        "print(\"Training images = \",TRAIN_IMG_NUM)\n",
        "print(\"Validation images = \",VALID_IMG_NUM)\n",
        "print(\"Test images = \",TEST_IMG_NUM)\n",
        "\n",
        "for image_name in ALL_IMAGES[:TRAIN_IMG_NUM]:\n",
        "    img = cv2.imread(image_name, cv2.IMREAD_UNCHANGED)\n",
        "    img_x_name = str(image_name.split('/')[-1]).split('.')[0]\n",
        "    img_x_id = str(str(image_name.split('/')[-1]).split('_')[-1]).split('.')[0]\n",
        "    mask_name = \"trainy/\"+'Y_img_'+str(img_x_id)+\".bmp\"\n",
        "    mask = cv2.imread(mask_name, cv2.IMREAD_UNCHANGED)\n",
        "    save_img_name = \"train_imgs/\"+img_x_name+\".bmp\"\n",
        "    save_mask_name = \"train_masks/\"+img_x_name+\".bmp\"\n",
        "    cv2.imwrite(save_img_name,img)\n",
        "    cv2.imwrite(save_mask_name,mask)\n",
        "\n",
        "for image_name in ALL_IMAGES[TRAIN_IMG_NUM:TRAIN_IMG_NUM+VALID_IMG_NUM]:\n",
        "    img = cv2.imread(image_name, cv2.IMREAD_UNCHANGED)\n",
        "    img_x_name = str(image_name.split('/')[-1]).split('.')[0]\n",
        "    img_x_id = str(str(image_name.split('/')[-1]).split('_')[-1]).split('.')[0]\n",
        "    mask_name = \"trainy/\"+'Y_img_'+str(img_x_id)+\".bmp\"\n",
        "    mask = cv2.imread(mask_name, cv2.IMREAD_UNCHANGED)\n",
        "    save_img_name = \"val_imgs/\"+img_x_name+\".bmp\"\n",
        "    save_mask_name = \"val_masks/\"+img_x_name+\".bmp\"\n",
        "    cv2.imwrite(save_img_name,img)\n",
        "    cv2.imwrite(save_mask_name,mask)\n",
        "\n",
        "for image_name in ALL_IMAGES[TEST_IMG_NUM:]:\n",
        "    img = cv2.imread(image_name, cv2.IMREAD_UNCHANGED)\n",
        "    img_x_name = str(image_name.split('/')[-1]).split('.')[0]\n",
        "    img_x_id = str(str(image_name.split('/')[-1]).split('_')[-1]).split('.')[0]\n",
        "    mask_name = \"trainy/\"+'Y_img_'+str(img_x_id)+\".bmp\"\n",
        "    mask = cv2.imread(mask_name, cv2.IMREAD_UNCHANGED)\n",
        "    save_img_name = \"test_imgs/\"+img_x_name+\".bmp\"\n",
        "    save_mask_name = \"test_masks/\"+img_x_name+\".bmp\"\n",
        "    cv2.imwrite(save_img_name,img)\n",
        "    cv2.imwrite(save_mask_name,mask)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl5RF59gYOVA",
        "outputId": "0064fefd-75ff-4956-9a2d-efcf6be8baa4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images =  140\n",
            "Validation images =  20\n",
            "Test images =  160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_imgs = glob.glob('train_imgs/*.bmp')\n",
        "all_train_masks = glob.glob('train_masks/*.bmp')\n",
        "all_val_imgs = glob.glob('val_imgs/*.bmp')\n",
        "all_val_masks = glob.glob('val_masks/*.bmp')\n",
        "all_test_imgs = glob.glob('test_imgs/*.bmp')\n",
        "all_test_masks = glob.glob('test_masks/*.bmp')\n",
        "print(\"Length of all_train_imgs = \",len(all_train_imgs))\n",
        "print(\"Length of all_train_masks = \",len(all_train_masks))\n",
        "print(\"Length of all_val_imgs = \",len(all_val_imgs))\n",
        "print(\"Length of all_val_masks = \",len(all_val_masks))\n",
        "print(\"Length of all_test_imgs = \",len(all_test_imgs))\n",
        "print(\"Length of all_test_masks = \",len(all_test_masks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyab8Dtva6-F",
        "outputId": "e3d35108-1f34-4944-881e-9a472d5189e0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of all_train_imgs =  140\n",
            "Length of all_train_masks =  140\n",
            "Length of all_val_imgs =  20\n",
            "Length of all_val_masks =  20\n",
            "Length of all_test_imgs =  40\n",
            "Length of all_test_masks =  40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# mostly torch imports and plot imports\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "# mostly torch imports and plot imports\n",
        "import torch\n",
        "import shutil\n",
        "import glob\n",
        "import pickle\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import torch.utils\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "import torchvision.transforms as T\n",
        "import torch.distributions\n",
        "torch.manual_seed(42)\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from matplotlib import rc, rcParams"
      ],
      "metadata": {
        "id": "U2C_ZJ9YYkXt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter CUDA/CPU mode"
      ],
      "metadata": {
        "id": "WHKjmJDtcbSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA  and stuffs\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda: {}'.format(use_cuda))\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device to be used : \",device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMYTEVwccdx",
        "outputId": "3b1de9d3-b903-4dfa-ae5c-a4444968dbb2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda: True\n",
            "Device to be used :  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the dump folders"
      ],
      "metadata": {
        "id": "HBtBhkuEcJCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FOLDER_NAME = \"checkpoint\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "FOLDER_NAME = \"inference_data\"\n",
        "\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "FOLDER_NAME = \"history\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(FOLDER_NAME)\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "btGqA69NYk0o"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evalutation metrics here"
      ],
      "metadata": {
        "id": "ajdDximqcQDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation metrics  here\n",
        "########################################################################################\n",
        "########################################################################################\n",
        "########################################################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0001\n",
        "    y_true = np.where((y_true > 0.5) & (y_true <= 1.), 1, y_true)\n",
        "    y_true = np.where((y_true > 0.0) & (y_true <= 0.5), 0, y_true)\n",
        "    y_pred = np.where((y_pred > 0.5) & (y_pred <= 1.), 1, y_pred)\n",
        "    y_pred = np.where((y_pred > 0.0) & (y_pred <= 0.5), 0, y_pred)\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "    smooth = 0.0001\n",
        "    y_true = np.where((y_true > 0.5) & (y_true <= 1.), 1, y_true)\n",
        "    y_true = np.where((y_true > 0.0) & (y_true <= 0.5), 0, y_true)\n",
        "    y_pred = np.where((y_pred > 0.5) & (y_pred <= 1.), 1, y_pred)\n",
        "    y_pred = np.where((y_pred > 0.0) & (y_pred <= 0.5), 0, y_pred)\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    union = np.sum(y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "    return intersection/union\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def dice_coef_multilabel(y_true, y_pred, numLabels):\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice += dice_coef(y_true[:,index,:,:], y_pred[:,index,:,:])\n",
        "    return dice/numLabels # taking average\n",
        "\n",
        "\n",
        "def jacard_multilabel(y_true, y_pred, numLabels):\n",
        "    jacard_sum=0\n",
        "    for index in range(numLabels):\n",
        "        jacard_sum += jacard(y_true[:,index,:,:], y_pred[:,index,:,:])\n",
        "    return jacard_sum/numLabels # taking average\n",
        "\n",
        "\n",
        "def accuracy_check(mask, prediction):\n",
        "    ims = [mask, prediction]\n",
        "    np_ims = []\n",
        "    for item in ims:\n",
        "        if 'str' in str(type(item)):\n",
        "            item = np.array(Image.open(item))\n",
        "        elif 'PIL' in str(type(item)):\n",
        "            item = np.array(item)\n",
        "        elif 'torch' in str(type(item)):\n",
        "            item = item.numpy()\n",
        "        np_ims.append(item)\n",
        "\n",
        "    compare = np.equal(np_ims[0], np_ims[1])\n",
        "    accuracy = np.sum(compare)\n",
        "\n",
        "    return accuracy/len(np_ims[0].flatten())\n",
        "\n",
        "\n",
        "def accuracy_check_for_batch(masks, predictions, batch_size):\n",
        "    total_acc = 0\n",
        "    for index in range(batch_size):\n",
        "        total_acc += accuracy_check(masks[index], predictions[index])\n",
        "    return total_acc/batch_size"
      ],
      "metadata": {
        "id": "KVfUkz6qYsQC"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U-Net model here"
      ],
      "metadata": {
        "id": "GFO4A5sOcVAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# U-Net model here\n",
        "########################################################################################\n",
        "########################################################################################\n",
        "########################################################################################\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class UNet_Sigmoid(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "\n",
        "        x = self.dconv_down4(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.dconv_up1(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "zl_VRoA_Y2CX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Image Augmentation stuffs that you can use"
      ],
      "metadata": {
        "id": "Oc_aCLVZci06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "####################\n",
        "def add_random_boxes(img, mask, n_k,size=32):\n",
        "    h,w = size,size\n",
        "    img = np.asarray(img)\n",
        "    mask = np.asarray(mask)\n",
        "    img_size = img.shape[1]\n",
        "    boxes = []\n",
        "    for k in range(n_k):\n",
        "        y,x = np.random.randint(0,img_size-w,(2,))\n",
        "        img[y:y+h,x:x+w] = 0\n",
        "        mask[y:y+h,x:x+w] = 0\n",
        "        boxes.append((x,y,h,w))\n",
        "    # img = Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "    return img, mask\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "from skimage.filters import gaussian\n",
        "from skimage.filters import unsharp_mask\n",
        "\n",
        "def transformer(image, mask):\n",
        "    # image and mask are PIL image object.\n",
        "    img_w, img_h = mask.size\n",
        "\n",
        "    # Random horizontal flipping\n",
        "    if random.random() > 0.5:\n",
        "        image = TF.hflip(image)\n",
        "        mask = TF.hflip(mask)\n",
        "\n",
        "    # Random vertical flipping\n",
        "    if random.random() > 0.5:\n",
        "        image = TF.vflip(image)\n",
        "        mask = TF.vflip(mask)\n",
        "\n",
        "    # Random affine\n",
        "    affine_param = transforms.RandomAffine.get_params(\n",
        "        degrees = [-180, 180], translate = [0.3,0.3],\n",
        "        img_size = [img_w, img_h], scale_ranges = [1, 1.3],\n",
        "        shears = [2,2])\n",
        "    image = TF.affine(image,\n",
        "                      affine_param[0], affine_param[1],\n",
        "                      affine_param[2], affine_param[3])\n",
        "    mask = TF.affine(mask,\n",
        "                     affine_param[0], affine_param[1],\n",
        "                     affine_param[2], affine_param[3])\n",
        "\n",
        "    image = np.array(image)\n",
        "    mask = np.array(mask)\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "5SnwKVC5Y86y"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the train and test data-loaders"
      ],
      "metadata": {
        "id": "EsX-CEl_coT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 1\n",
        "\n",
        "# Use the data generator to load the dataset\n",
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, image_list,mask_path):\n",
        "        self.files = image_list\n",
        "        self.select_path = mask_path\n",
        "\n",
        "    #NUMBER OF FILES IN THE DATASET\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    #GETTING SINGLE PAIR OF DATA\n",
        "    def __getitem__(self,idx):\n",
        "        file_name = self.files[idx].split('/')[-1]\n",
        "        mask_name = self.select_path+file_name\n",
        "        img = cv2.imread(self.files[idx],cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(mask_name,cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        mask = mask/255.0\n",
        "        img_transpose = np.transpose(img, (2, 0, 1))\n",
        "        mask = np.expand_dims(mask, axis=2)\n",
        "        mask_one_hot_transpose = np.transpose(mask, (2, 0, 1))\n",
        "        return torch.FloatTensor(img_transpose/img_transpose.max()), torch.FloatTensor(mask_one_hot_transpose)\n",
        "\n",
        "\n",
        "class TestDataGenerator(Dataset):\n",
        "    def __init__(self, image_list,mask_path):\n",
        "        self.files = image_list\n",
        "        self.select_path = mask_path\n",
        "\n",
        "    #NUMBER OF FILES IN THE DATASET\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    #GETTING SINGLE PAIR OF DATA\n",
        "    def __getitem__(self,idx):\n",
        "        file_name = self.files[idx].split('/')[-1]\n",
        "        mask_name = self.select_path+file_name\n",
        "        img = cv2.imread(self.files[idx],cv2.IMREAD_COLOR)\n",
        "        mask = cv2.imread(mask_name,cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        mask = mask/255.0\n",
        "        img_transpose = np.transpose(img, (2, 0, 1))\n",
        "        mask = np.expand_dims(mask, axis=2)\n",
        "        mask_one_hot_transpose = np.transpose(mask, (2, 0, 1))\n",
        "        print(\"Unique values of image == \",np.unique(torch.FloatTensor(img_transpose/img_transpose.max())))\n",
        "        return torch.FloatTensor(img_transpose/img_transpose.max()), torch.FloatTensor(mask_one_hot_transpose)\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_path, batch_size=2, num_workers=10, shuffle=True):\n",
        "    dataset = DataGenerator(image_list, mask_path)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "    return data_loader\n",
        "\n",
        "def load_test_data(image_list, mask_path, batch_size=2, num_workers=10, shuffle=True):\n",
        "    dataset = TestDataGenerator(image_list, mask_path)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "    return data_loader\n",
        "\n",
        "def get_image_address(image_data_folder):\n",
        "    image_address_list = []\n",
        "    image_address_list = glob.glob(image_data_folder+\"/*.bmp\")\n",
        "    print(\"Number of Files : \", len(image_address_list))\n",
        "    for img_addr in image_address_list:\n",
        "        try :\n",
        "            img = cv2.imread(img_addr)\n",
        "            x = img.shape\n",
        "        except :\n",
        "            image_address_list.remove(img_addr)\n",
        "            os.remove(img_addr)\n",
        "    print(\"Number of Files after removing : \", len(image_address_list))\n",
        "    return image_address_list"
      ],
      "metadata": {
        "id": "ljiEKBcfZHYZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and load checkpoint"
      ],
      "metadata": {
        "id": "7mjeyomrcuLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# save checkpoint in pytorch\n",
        "def save_ckp(checkpoint, checkpoint_path):\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "\n",
        "# load checkpoint in pytorch\n",
        "def load_ckp(checkpoint_path, model, model_opt):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model_opt.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, model_opt, checkpoint['epoch']\n"
      ],
      "metadata": {
        "id": "E-61-lqZctrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Val-Test pipeline"
      ],
      "metadata": {
        "id": "kWl8pxT4cyqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train, Val and Test\n",
        "#####################################################################\n",
        "\n",
        "def train_epoch(train_loader, model, optimizer, epoch):\n",
        "    print(\"\\n\\n---------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "    progress_bar = tqdm(enumerate(train_loader))\n",
        "    total_loss = 0.0\n",
        "    total_dice = 0.0\n",
        "    total_jacard = 0.0\n",
        "    total_acc = 0.0\n",
        "    N = 0\n",
        "    for step, (inp__, gt__) in progress_bar:\n",
        "        # if mask_1 is None and low_res_img is None:\n",
        "        #     continue\n",
        "        model.train()\n",
        "\n",
        "        #TRANSFERRING DATA TO DEVICE\n",
        "        inp__ = inp__.to(device)\n",
        "        gt__ = gt__.to(device)\n",
        "\n",
        "        # clear the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #GETTING THE PREDICTED IMAGE\n",
        "        pred_img = model.forward(inp__)\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_img, gt__)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "        pred_img_detached = pred_img.cpu().detach().numpy()\n",
        "        gt_img_detached = gt__.cpu().detach().numpy()\n",
        "        numLabels = NUM_LABELS\n",
        "        dice = dice_coef(gt_img_detached, pred_img_detached)\n",
        "        jacard_ = jacard(gt_img_detached, pred_img_detached)\n",
        "        acc_ = accuracy_check_for_batch(np.round(pred_img_detached), gt_img_detached, pred_img_detached.shape[0])\n",
        "        total_dice += float(dice)\n",
        "        total_jacard += float(jacard_)\n",
        "        total_acc += float(acc_)\n",
        "        N += 1\n",
        "\n",
        "        #BACKPROPAGATING THE LOSS\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #DISPLAYING THE LOSS\n",
        "        progress_bar.set_description(\"Epoch: {} -  Loss: {} - Acc: {} - Dice: {} - Jaccard: {}\".format(epoch, loss, acc_, dice, jacard_))\n",
        "\n",
        "    mean_loss = total_loss/N\n",
        "    mean_dice = total_dice/N\n",
        "    mean_jacard = total_jacard/N\n",
        "    mean_acc = total_acc/N\n",
        "\n",
        "    with open(\"history/train_logs.txt\", \"a\") as text_file:\n",
        "        text_file.write(\"{} {} {} {} {}\\n\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "    print(\"[Training] Training Epoch: {} |  Loss: {} | Acc: {} | Dice: {} | Jaccard: {}\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "\n",
        "    return model, optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def val_epoch(val_loader, model, optimizer, epoch):\n",
        "    progress_bar = tqdm(enumerate(val_loader))\n",
        "    total_loss = 0.0\n",
        "    total_dice = 0.0\n",
        "    total_jacard = 0.0\n",
        "    total_acc = 0.0\n",
        "    N = 0\n",
        "    for step, (inp__, gt__) in progress_bar:\n",
        "        if inp__ is None and gt__ is None:\n",
        "            continue\n",
        "\n",
        "        inp__ = inp__.to(device)\n",
        "        gt__ = gt__.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        pred_img = model.forward(inp__)\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_img, gt__)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "        pred_img_detached = pred_img.cpu().detach().numpy()\n",
        "        gt_img_detached = gt__.cpu().detach().numpy()\n",
        "        numLabels = NUM_LABELS\n",
        "        #dice = dice_coef(gt_img_detached, pred_img_detached)\n",
        "        dice = dice_coef(gt_img_detached, pred_img_detached)\n",
        "        #dice_coef(gt_img_detached, pred_img_detached)\n",
        "        jacard_ = jacard(gt_img_detached, pred_img_detached)\n",
        "        acc_ = accuracy_check_for_batch(np.round(pred_img_detached), gt_img_detached, pred_img_detached.shape[0])\n",
        "        total_dice += float(dice)\n",
        "        total_jacard += float(jacard_)\n",
        "        total_acc += float(acc_)\n",
        "        N += 1\n",
        "        progress_bar.set_description(\"Epoch: {} -  Loss: {} - Acc: {} - Dice: {} - Jaccard: {}\".format(epoch, loss, acc_, dice, jacard_))\n",
        "\n",
        "    # mean_hausdroff = total_hausdroff/N\n",
        "    mean_loss = total_loss/N\n",
        "    mean_dice = total_dice/N\n",
        "    mean_jacard = total_jacard/N\n",
        "    mean_acc = total_acc/N\n",
        "\n",
        "    with open(\"history/val_logs.txt\", \"a\") as text_file:\n",
        "        text_file.write(\"{} {} {} {} {}\\n\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "\n",
        "    print(\"[Validation] Validation Epoch: {} |  Loss: {} | Acc: {} | Dice: {} | Jaccard: {}\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "\n",
        "\n",
        "\n",
        "def test_epoch(test_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(test_loader))\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #SETTING THE NUMBER OF IMAGES TO CHECK AFTER EACH ITERATION\n",
        "    no_img_to_write = 20\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_dice = 0.0\n",
        "    total_jacard = 0.0\n",
        "    total_acc = 0.0\n",
        "    N = 0\n",
        "    for step, (inp__, gt__) in progress_bar:\n",
        "        if inp__ is None and gt__ is None:\n",
        "            continue\n",
        "\n",
        "        inp__ = inp__.to(device)\n",
        "        gt__ = gt__.to(device)\n",
        "\n",
        "\n",
        "        #PREDICTED IMAGE\n",
        "        pred_img = model.forward(inp__)\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_img, gt__)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "        pred_img_detached = pred_img.cpu().detach().numpy()\n",
        "        gt_img_detached = gt__.cpu().detach().numpy()\n",
        "        numLabels = NUM_LABELS\n",
        "        dice = dice_coef(gt_img_detached, pred_img_detached)\n",
        "        jacard_ = jacard(gt_img_detached, pred_img_detached)\n",
        "        acc_ = accuracy_check_for_batch(np.round(pred_img_detached), gt_img_detached, pred_img_detached.shape[0])\n",
        "        total_dice += float(dice)\n",
        "        total_jacard += float(jacard_)\n",
        "        total_acc += float(acc_)\n",
        "        N += 1\n",
        "\n",
        "        progress_bar.set_description(\"[Test] Epoch: {} -  Loss: {} - Acc: {} - Dice: {} - Jaccard: {}\".format(epoch, loss, acc_, dice, jacard_))\n",
        "\n",
        "        #WRITING THE IMAGES INTO THE SPECIFIED DIRECTORY\n",
        "        if(step < no_img_to_write):\n",
        "\n",
        "            p_img = pred_img.cpu().numpy() * 255\n",
        "            gt_img = gt__.cpu().numpy() * 255\n",
        "            inp_img = inp__.cpu().numpy() * 255.0\n",
        "\n",
        "            #FOLDER PATH TO WRITE THE INFERENCES\n",
        "            inference_folder = \"inference_data\"\n",
        "            if not os.path.isdir(inference_folder):\n",
        "                os.mkdir(inference_folder)\n",
        "\n",
        "            print(\"\\n Saving inferences at epoch === \",epoch)\n",
        "            for p_image_loop, gt_img_loop, inp_img_loop in zip(p_img, gt_img, inp_img):\n",
        "\n",
        "                p_image_loop = np.transpose(p_image_loop, (1, 2, 0))\n",
        "                cv2.imwrite(os.path.join(inference_folder, \"img_\"+str(step)+\"_pred.png\"),p_image_loop.round())\n",
        "\n",
        "                gt_img_loop = np.transpose(gt_img_loop, (1, 2, 0))\n",
        "                cv2.imwrite(os.path.join(inference_folder, \"img_\"+str(step)+\"_gt.png\"), gt_img_loop)\n",
        "\n",
        "                inp_img_loop = np.transpose(inp_img_loop, (1, 2, 0))\n",
        "                cv2.imwrite(os.path.join(inference_folder, \"img_\"+str(step)+\"_inp.png\"), inp_img_loop)\n",
        "\n",
        "    mean_loss = total_loss/N\n",
        "    mean_dice = total_dice/N\n",
        "    mean_jacard = total_jacard/N\n",
        "    mean_acc = total_acc/N\n",
        "\n",
        "    with open(\"history/test_logs.txt\", \"a\") as text_file:\n",
        "        text_file.write(\"{} {} {} {} {}\\n\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "\n",
        "    print(\"Test Epoch: {} |  Loss: {} | Accuracy: {} | Dice: {} | Jaccard: {}\".format(epoch, mean_loss, mean_acc, mean_dice, mean_jacard))\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vjEEm5tSZLFL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to integrate all the train, validation, test and checkpointing stuffs using epoch numbers"
      ],
      "metadata": {
        "id": "hJUouNcYc20y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_val_test(train_loader, val_loader, test_loader, model, optimizer, n_epoch, resume):\n",
        "\n",
        "    #PATH TO SAVE THE CHECKPOINT\n",
        "    checkpoint_path = \"checkpoint/checkpoint.pt\"\n",
        "\n",
        "    epoch = 0\n",
        "    #IF TRAINING IS TO RESUMED FROM A CERTAIN CHECKPOINT\n",
        "    if resume:\n",
        "        model, optimizer, epoch = load_ckp(\n",
        "            checkpoint_path, model, optimizer)\n",
        "\n",
        "    while epoch <= n_epoch:\n",
        "        epoch += 1\n",
        "        model, optimizer = train_epoch(train_loader, model, optimizer, epoch)\n",
        "\n",
        "        #CHECKPOINT CREATION\n",
        "        checkpoint = {'epoch': epoch+1, 'state_dict': model.state_dict(),\n",
        "                      'optimizer': optimizer.state_dict()}\n",
        "\n",
        "        #CHECKPOINT SAVING\n",
        "        save_ckp(checkpoint, checkpoint_path)\n",
        "        print(\"Checkpoint Saved\")\n",
        "\n",
        "        #CHECKPOINT LOADING\n",
        "        model, optimizer, epoch = load_ckp(checkpoint_path, model, optimizer)\n",
        "        print(\"Checkpoint Loaded\")\n",
        "        with torch.no_grad():\n",
        "            val_epoch(val_loader, model, optimizer, epoch)\n",
        "\n",
        "    print(\"************************ Final Test Epoch *****************************\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_epoch(test_loader, model, optimizer, epoch)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q2RHUekLZPUT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main function to load all the data, set the optimizer etc."
      ],
      "metadata": {
        "id": "pyfAByJjc_VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    train_image_address_list = get_image_address(\"train_imgs/\")\n",
        "    random.shuffle(train_image_address_list)\n",
        "\n",
        "    train_loader = load_data(train_image_address_list, mask_path=\"train_masks/\", batch_size=2, num_workers=2, shuffle=True)\n",
        "    check = iter(train_loader)\n",
        "    val_image_address_list = get_image_address(\"val_imgs/\")\n",
        "\n",
        "    random.shuffle(val_image_address_list)\n",
        "    val_loader = load_data(val_image_address_list, mask_path=\"val_masks/\", batch_size=2, num_workers=2, shuffle=True)\n",
        "    check = iter(val_loader)\n",
        "\n",
        "    test_image_address_list = get_image_address(\"test_imgs/\")\n",
        "    random.shuffle(test_image_address_list)\n",
        "    test_loader = load_data(test_image_address_list, mask_path=\"test_masks/\", batch_size=2, num_workers=2, shuffle=True)\n",
        "    check = iter(test_loader)\n",
        "\n",
        "    print(\"Train : {} Val : {} \".format(len(train_image_address_list), len(val_image_address_list)))\n",
        "\n",
        "    #1. CALLING THE MODEL - U-Net, batch_size=2, num_workers=2, lr=1e-04\n",
        "    model = UNet_Sigmoid(1)\n",
        "    model = model.to(device)\n",
        "    summary(model, input_size=(3, 128, 128))\n",
        "\n",
        "    #DEFINING THE OPTIMIZER\n",
        "    optimizer = optim.Adam(\n",
        "        [p for p in model.parameters() if p.requires_grad], lr=1e-04, weight_decay=5e-4)\n",
        "\n",
        "    n_epoch = 50\n",
        "\n",
        "    #INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\n",
        "    resume = False\n",
        "    train_val_test(train_loader, val_loader, test_loader, model, optimizer, n_epoch, resume)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPmuR5TRZUlB",
        "outputId": "572f49cc-3129-4f3b-fff7-dafed16adb4b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting the main function ----\n",
            "Number of Files :  140\n",
            "Number of Files after removing :  140\n",
            "Number of Files :  20\n",
            "Number of Files after removing :  20\n",
            "Number of Files :  40\n",
            "Number of Files after removing :  40\n",
            "Train : 140 Val : 20 \n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "            Conv2d-4         [-1, 64, 128, 128]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 128, 128]             128\n",
            "              ReLU-6         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8          [-1, 128, 64, 64]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 64, 64]             256\n",
            "             ReLU-10          [-1, 128, 64, 64]               0\n",
            "           Conv2d-11          [-1, 128, 64, 64]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 64, 64]             256\n",
            "             ReLU-13          [-1, 128, 64, 64]               0\n",
            "        MaxPool2d-14          [-1, 128, 32, 32]               0\n",
            "           Conv2d-15          [-1, 256, 32, 32]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 32, 32]             512\n",
            "             ReLU-17          [-1, 256, 32, 32]               0\n",
            "           Conv2d-18          [-1, 256, 32, 32]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 32, 32]             512\n",
            "             ReLU-20          [-1, 256, 32, 32]               0\n",
            "        MaxPool2d-21          [-1, 256, 16, 16]               0\n",
            "           Conv2d-22          [-1, 512, 16, 16]       1,180,160\n",
            "      BatchNorm2d-23          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-24          [-1, 512, 16, 16]               0\n",
            "           Conv2d-25          [-1, 512, 16, 16]       2,359,808\n",
            "      BatchNorm2d-26          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-27          [-1, 512, 16, 16]               0\n",
            "         Upsample-28          [-1, 512, 32, 32]               0\n",
            "           Conv2d-29          [-1, 256, 32, 32]       1,769,728\n",
            "      BatchNorm2d-30          [-1, 256, 32, 32]             512\n",
            "             ReLU-31          [-1, 256, 32, 32]               0\n",
            "           Conv2d-32          [-1, 256, 32, 32]         590,080\n",
            "      BatchNorm2d-33          [-1, 256, 32, 32]             512\n",
            "             ReLU-34          [-1, 256, 32, 32]               0\n",
            "         Upsample-35          [-1, 256, 64, 64]               0\n",
            "           Conv2d-36          [-1, 128, 64, 64]         442,496\n",
            "      BatchNorm2d-37          [-1, 128, 64, 64]             256\n",
            "             ReLU-38          [-1, 128, 64, 64]               0\n",
            "           Conv2d-39          [-1, 128, 64, 64]         147,584\n",
            "      BatchNorm2d-40          [-1, 128, 64, 64]             256\n",
            "             ReLU-41          [-1, 128, 64, 64]               0\n",
            "         Upsample-42        [-1, 128, 128, 128]               0\n",
            "           Conv2d-43         [-1, 64, 128, 128]         110,656\n",
            "      BatchNorm2d-44         [-1, 64, 128, 128]             128\n",
            "             ReLU-45         [-1, 64, 128, 128]               0\n",
            "           Conv2d-46         [-1, 64, 128, 128]          36,928\n",
            "      BatchNorm2d-47         [-1, 64, 128, 128]             128\n",
            "             ReLU-48         [-1, 64, 128, 128]               0\n",
            "           Conv2d-49          [-1, 1, 128, 128]              65\n",
            "================================================================\n",
            "Total params: 7,788,545\n",
            "Trainable params: 7,788,545\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 205.62\n",
            "Params size (MB): 29.71\n",
            "Estimated Total Size (MB): 235.52\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 23 -  Loss: 0.0888863205909729 - Acc: 0.980010986328125 - Dice: 0.9730233251695067 - Jaccard: 0.947463870048523: : 70it [00:08,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 23 |  Loss: 0.18352265655994415 | Acc: 0.9373699733189174 | Dice: 0.9112663090247424 | Jaccard: 0.846001717022487\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 24 -  Loss: 0.38152655959129333 - Acc: 0.8269729614257812 - Dice: 0.7513650527023403 - Jaccard: 0.6017491817474365: : 10it [00:00, 20.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 24 |  Loss: 0.37019628286361694 | Acc: 0.8555625915527344 | Dice: 0.8361379039690633 | Jaccard: 0.7276356458663941\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 25 -  Loss: 0.12611716985702515 - Acc: 0.9554443359375 - Dice: 0.910437932317356 - Jaccard: 0.8355998992919922: : 70it [00:08,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 25 |  Loss: 0.1594979614019394 | Acc: 0.942220197405134 | Dice: 0.9152315358855887 | Jaccard: 0.8487675062247685\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 26 -  Loss: 0.046911220997571945 - Acc: 0.9877548217773438 - Dice: 0.9269197099092563 - Jaccard: 0.8637934327125549: : 10it [00:00, 19.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 26 |  Loss: 0.18455012142658234 | Acc: 0.9269264221191407 | Dice: 0.8975368200914413 | Jaccard: 0.8175832509994507\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 27 -  Loss: 0.22883456945419312 - Acc: 0.904388427734375 - Dice: 0.7484218539912778 - Jaccard: 0.5979825258255005: : 70it [00:08,  8.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 27 |  Loss: 0.15649254620075226 | Acc: 0.943410382952009 | Dice: 0.9110251382802573 | Jaccard: 0.8414019192968096\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 28 -  Loss: 0.5518957376480103 - Acc: 0.7391891479492188 - Dice: 0.7483893099770408 - Jaccard: 0.597940981388092: : 10it [00:00, 20.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 28 |  Loss: 0.22723403573036194 | Acc: 0.9220077514648437 | Dice: 0.9001185539273104 | Jaccard: 0.8224467933177948\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 29 -  Loss: 0.16836152970790863 - Acc: 0.9228439331054688 - Dice: 0.8950832202200628 - Jaccard: 0.8100910782814026: : 70it [00:07,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 29 |  Loss: 0.16156858205795288 | Acc: 0.9391842433384486 | Dice: 0.9077660170125561 | Jaccard: 0.8381702572107315\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 30 -  Loss: 0.14536038041114807 - Acc: 0.9379501342773438 - Dice: 0.9324671881811241 - Jaccard: 0.8734787106513977: : 10it [00:00, 18.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 30 |  Loss: 0.189841628074646 | Acc: 0.9202751159667969 | Dice: 0.8801837164878344 | Jaccard: 0.8015475898981095\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 31 -  Loss: 0.14428335428237915 - Acc: 0.9392776489257812 - Dice: 0.9030526670153889 - Jaccard: 0.8232415914535522: : 70it [00:07,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 31 |  Loss: 0.152564138174057 | Acc: 0.9481772286551339 | Dice: 0.9239071425943928 | Jaccard: 0.8618105888366699\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 32 -  Loss: 0.13208596408367157 - Acc: 0.9571609497070312 - Dice: 0.94140882165853 - Jaccard: 0.8893035054206848: : 10it [00:00, 20.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 32 |  Loss: 0.25574037432670593 | Acc: 0.8956626892089844 | Dice: 0.8769705302646897 | Jaccard: 0.7916630893945694\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 33 -  Loss: 0.08827266097068787 - Acc: 0.9659194946289062 - Dice: 0.9593439828289281 - Jaccard: 0.9218646287918091: : 70it [00:08,  8.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 33 |  Loss: 0.1482209414243698 | Acc: 0.9469093322753906 | Dice: 0.9212760091692709 | Jaccard: 0.8578563954148973\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 34 -  Loss: 0.1305321455001831 - Acc: 0.9526748657226562 - Dice: 0.8722967367025717 - Jaccard: 0.7735161781311035: : 10it [00:00, 20.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 34 |  Loss: 0.187783882021904 | Acc: 0.9243293762207031 | Dice: 0.8855300250799027 | Jaccard: 0.810866829752922\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 35 -  Loss: 0.11251140385866165 - Acc: 0.9586639404296875 - Dice: 0.909929241678467 - Jaccard: 0.8347432613372803: : 70it [00:08,  8.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 35 |  Loss: 0.15674889087677002 | Acc: 0.9449176243373326 | Dice: 0.9177840900219861 | Jaccard: 0.8511473493916648\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 36 -  Loss: 0.1074071004986763 - Acc: 0.9509201049804688 - Dice: 0.8677129562339799 - Jaccard: 0.7663365602493286: : 10it [00:00, 17.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 36 |  Loss: 0.19269852340221405 | Acc: 0.908880615234375 | Dice: 0.8874214712221355 | Jaccard: 0.8067354023456573\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 37 -  Loss: 0.07511694729328156 - Acc: 0.9802322387695312 - Dice: 0.9505332078951251 - Jaccard: 0.9057296514511108: : 70it [00:08,  8.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 37 |  Loss: 0.14370808005332947 | Acc: 0.9485885620117187 | Dice: 0.9203547149082484 | Jaccard: 0.8571001819201878\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 38 -  Loss: 0.10042503476142883 - Acc: 0.9716339111328125 - Dice: 0.9687301922970918 - Jaccard: 0.9393566846847534: : 10it [00:00, 21.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 38 |  Loss: 0.17204692959785461 | Acc: 0.9302330017089844 | Dice: 0.9002593093723791 | Jaccard: 0.8242182791233063\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 39 -  Loss: 0.14391465485095978 - Acc: 0.9379806518554688 - Dice: 0.9030104516889903 - Jaccard: 0.8231714367866516: : 70it [00:07,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 39 |  Loss: 0.136617049574852 | Acc: 0.9488369532993861 | Dice: 0.9226427970265094 | Jaccard: 0.8610921604292733\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 40 -  Loss: 0.15069858729839325 - Acc: 0.933135986328125 - Dice: 0.9483724585836508 - Jaccard: 0.9018140435218811: : 10it [00:00, 20.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 40 |  Loss: 0.16155119240283966 | Acc: 0.9321678161621094 | Dice: 0.8831296604196043 | Jaccard: 0.8032901167869568\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 41 -  Loss: 0.10289975255727768 - Acc: 0.9630813598632812 - Dice: 0.9131186855503426 - Jaccard: 0.8401273488998413: : 70it [00:07,  8.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 41 |  Loss: 0.15304164588451385 | Acc: 0.9458350045340401 | Dice: 0.9167451456167836 | Jaccard: 0.8523496883256095\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 42 -  Loss: 0.1621592491865158 - Acc: 0.9424591064453125 - Dice: 0.9155804577133575 - Jaccard: 0.844304621219635: : 10it [00:00, 20.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 42 |  Loss: 0.24151642620563507 | Acc: 0.9024467468261719 | Dice: 0.8854645936714787 | Jaccard: 0.8030771553516388\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 43 -  Loss: 0.09561961889266968 - Acc: 0.9659805297851562 - Dice: 0.9052244566628286 - Jaccard: 0.8268585205078125: : 70it [00:07,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 43 |  Loss: 0.1416119635105133 | Acc: 0.948189217703683 | Dice: 0.9226854473791649 | Jaccard: 0.8609118419034141\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 44 -  Loss: 0.12160157412290573 - Acc: 0.972076416015625 - Dice: 0.911588119888454 - Jaccard: 0.8375396728515625: : 10it [00:00, 17.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 44 |  Loss: 0.16445055603981018 | Acc: 0.9347679138183593 | Dice: 0.9122026282993344 | Jaccard: 0.8401764392852783\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 45 -  Loss: 0.11099831759929657 - Acc: 0.9605331420898438 - Dice: 0.9090292690152761 - Jaccard: 0.8332297205924988: : 70it [00:07,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 45 |  Loss: 0.1513439565896988 | Acc: 0.9413157871791294 | Dice: 0.9142584127075801 | Jaccard: 0.8476653716393879\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 46 -  Loss: 0.22811681032180786 - Acc: 0.8896255493164062 - Dice: 0.7039673625078736 - Jaccard: 0.5431709885597229: : 10it [00:00, 20.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 46 |  Loss: 0.1787782460451126 | Acc: 0.9307502746582031 | Dice: 0.8976005208142557 | Jaccard: 0.820579445362091\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 47 -  Loss: 0.36446574330329895 - Acc: 0.8256759643554688 - Dice: 0.7402740045779824 - Jaccard: 0.5876468420028687: : 70it [00:08,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 47 |  Loss: 0.14164027571678162 | Acc: 0.9476068769182477 | Dice: 0.9209722698384976 | Jaccard: 0.8577516734600067\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 48 -  Loss: 0.15454278886318207 - Acc: 0.934783935546875 - Dice: 0.9133045580661011 - Jaccard: 0.8404420614242554: : 10it [00:00, 20.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 48 |  Loss: 0.26220035552978516 | Acc: 0.8906776428222656 | Dice: 0.8560172409951731 | Jaccard: 0.7694890618324279\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 49 -  Loss: 0.1700117141008377 - Acc: 0.928314208984375 - Dice: 0.9335437437809394 - Jaccard: 0.8753699064254761: : 70it [00:08,  8.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 49 |  Loss: 0.18005679547786713 | Acc: 0.935740007672991 | Dice: 0.9064158435883276 | Jaccard: 0.83616561123303\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 50 -  Loss: 0.21636676788330078 - Acc: 0.9084854125976562 - Dice: 0.8674508368161505 - Jaccard: 0.7659277319908142: : 10it [00:00, 21.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 50 |  Loss: 0.17529618740081787 | Acc: 0.9283973693847656 | Dice: 0.8950949684455803 | Jaccard: 0.8175874829292298\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 51 -  Loss: 0.10013596713542938 - Acc: 0.9649276733398438 - Dice: 0.9572773657805719 - Jaccard: 0.9180555939674377: : 70it [00:07,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] Training Epoch: 51 |  Loss: 0.1283828616142273 | Acc: 0.9518438066755023 | Dice: 0.9285838672710117 | Jaccard: 0.8691147071974618\n",
            "Checkpoint Saved\n",
            "Checkpoint Loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 52 -  Loss: 0.11723795533180237 - Acc: 0.9663467407226562 - Dice: 0.8954529363829524 - Jaccard: 0.8106969594955444: : 10it [00:00, 20.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] Validation Epoch: 52 |  Loss: 0.1680155098438263 | Acc: 0.9325592041015625 | Dice: 0.9120001256300092 | Jaccard: 0.839715051651001\n",
            "************************ Final Test Epoch *****************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[Test] Epoch: 52 -  Loss: 0.052819184958934784 - Acc: 0.981353759765625 - Dice: 0.9322530817683772 - Jaccard: 0.8731030225753784: : 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.1439286470413208 - Acc: 0.9519577026367188 - Dice: 0.8955998668988621 - Jaccard: 0.8109378218650818: : 2it [00:00, 13.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch === "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.050094857811927795 - Acc: 0.9848480224609375 - Dice: 0.9515396123407761 - Jaccard: 0.9075589776039124: : 4it [00:00, 13.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.25319376587867737 - Acc: 0.8924560546875 - Dice: 0.9346606856167818 - Jaccard: 0.8773361444473267: : 6it [00:00, 13.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.05726483464241028 - Acc: 0.9775772094726562 - Dice: 0.9760712836306016 - Jaccard: 0.9532609581947327: : 8it [00:00, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.07344847917556763 - Acc: 0.9754104614257812 - Dice: 0.9567653261350982 - Jaccard: 0.9171141982078552: : 8it [00:00, 13.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.29391032457351685 - Acc: 0.8756027221679688 - Dice: 0.8205421790194285 - Jaccard: 0.6956943869590759: : 10it [00:00, 14.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.08151714503765106 - Acc: 0.9737701416015625 - Dice: 0.9530401448909439 - Jaccard: 0.91029292345047: : 12it [00:00, 14.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.1857537478208542 - Acc: 0.917877197265625 - Dice: 0.8187490281222471 - Jaccard: 0.6931203007698059: : 14it [00:01, 14.43it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.0796670913696289 - Acc: 0.9778976440429688 - Dice: 0.9106221138596098 - Jaccard: 0.8359102010726929: : 18it [00:01, 14.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n",
            "\n",
            " Saving inferences at epoch ===  52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test] Epoch: 52 -  Loss: 0.10149592906236649 - Acc: 0.9619369506835938 - Dice: 0.9311562092635588 - Jaccard: 0.8711808323860168: : 20it [00:01, 13.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Saving inferences at epoch ===  52\n",
            "Test Epoch: 52 |  Loss: 0.15378613770008087 | Accuracy: 0.9406269073486329 | Dice: 0.9066531451843179 | Jaccard: 0.8329307198524475\n",
            "---------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the code"
      ],
      "metadata": {
        "id": "TutBAYpjdEcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting the main function ----\")\n",
        "    main()"
      ],
      "metadata": {
        "id": "MED152ZybbyL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}